{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA2j6eZaLnUh",
        "outputId": "af692fe3-a53a-4422-cdd8-be421efe8993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data…\n",
            "Total samples: 3999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training CustomCNN\n",
            "Epoch 1/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 236ms/step - accuracy: 0.1433 - loss: 2.2172 - val_accuracy: 0.2188 - val_loss: 2.0375\n",
            "Epoch 2/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 223ms/step - accuracy: 0.2680 - loss: 1.9314 - val_accuracy: 0.2844 - val_loss: 1.8790\n",
            "Epoch 3/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 227ms/step - accuracy: 0.3902 - loss: 1.6705 - val_accuracy: 0.2562 - val_loss: 1.9470\n",
            "Epoch 4/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 234ms/step - accuracy: 0.5278 - loss: 1.3382 - val_accuracy: 0.2906 - val_loss: 1.9451\n",
            "Epoch 5/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 227ms/step - accuracy: 0.6692 - loss: 0.9542 - val_accuracy: 0.2656 - val_loss: 2.3540\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step\n",
            "CustomCNN Accuracy: 0.271  F1: 0.276\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "Training MobileNetV2\n",
            "Epoch 1/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 137ms/step - accuracy: 0.1587 - loss: 2.2594 - val_accuracy: 0.2000 - val_loss: 2.1075\n",
            "Epoch 2/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 122ms/step - accuracy: 0.2713 - loss: 1.9014 - val_accuracy: 0.2438 - val_loss: 2.0321\n",
            "Epoch 3/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.3757 - loss: 1.6877 - val_accuracy: 0.2531 - val_loss: 2.0203\n",
            "Epoch 4/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - accuracy: 0.4106 - loss: 1.6186 - val_accuracy: 0.2875 - val_loss: 2.0755\n",
            "Epoch 5/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 111ms/step - accuracy: 0.4560 - loss: 1.5161 - val_accuracy: 0.2750 - val_loss: 2.0617\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 229ms/step\n",
            "MobileNetV2 Accuracy: 0.266  F1: 0.239\n",
            "\n",
            "Comparison => CustomCNN Acc:0.271 F1:0.276 | MobileNetV2 Acc:0.266 F1:0.239\n",
            "\n",
            "Training Valence/Arousal regressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 93ms/step - loss: 0.1961 - val_loss: 0.1740\n",
            "Epoch 2/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 97ms/step - loss: 0.1840 - val_loss: 0.1719\n",
            "Epoch 3/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - loss: 0.1793 - val_loss: 0.1719\n",
            "Epoch 4/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 101ms/step - loss: 0.1805 - val_loss: 0.1711\n",
            "Epoch 5/5\n",
            "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 91ms/step - loss: 0.1846 - val_loss: 0.1711\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step\n",
            "Valence/Arousal RMSE:0.426  Corr V:0.093  Corr A:0.085\n"
          ]
        }
      ],
      "source": [
        "import os, glob, numpy as np, cv2, random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# ------------------ Paths ------------------\n",
        "IMG_DIR = r\"/content/drive/MyDrive/Dataset/images\"\n",
        "ANN_DIR = r\"/content/drive/MyDrive/Dataset/annotations\"\n",
        "\n",
        "\n",
        "# ------------------ Load dataset ------------------\n",
        "def load_dataset(limit=None):\n",
        "    X, y_cls, y_val, y_aro = [], [], [], []\n",
        "    img_files = glob.glob(os.path.join(IMG_DIR, \"*.jpg\"))\n",
        "    if limit: img_files = img_files[:limit]\n",
        "    for img_path in img_files:\n",
        "        stem = os.path.splitext(os.path.basename(img_path))[0]\n",
        "        try:\n",
        "            exp = np.load(os.path.join(ANN_DIR, f\"{stem}_exp.npy\"))\n",
        "            val = np.load(os.path.join(ANN_DIR, f\"{stem}_val.npy\"))\n",
        "            aro = np.load(os.path.join(ANN_DIR, f\"{stem}_aro.npy\"))\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (96, 96))\n",
        "        X.append(img/255.0)\n",
        "        y_cls.append(int(exp))\n",
        "        y_val.append(float(val))\n",
        "        y_aro.append(float(aro))\n",
        "    X = np.array(X, dtype=\"float32\")\n",
        "    y_cls = to_categorical(y_cls, num_classes=8)\n",
        "    y_val, y_aro = np.array(y_val), np.array(y_aro)\n",
        "    return X, y_cls, y_val, y_aro\n",
        "\n",
        "print(\"Loading data…\")\n",
        "X, y_cls, y_val, y_aro = load_dataset()   # remove limit for full run\n",
        "print(\"Total samples:\", len(X))\n",
        "\n",
        "# Train/val split\n",
        "X_train, X_test, y_cls_train, y_cls_test, y_val_train, y_val_test, y_aro_train, y_aro_test = \\\n",
        "    train_test_split(X, y_cls, y_val, y_aro, test_size=0.2, random_state=42)\n",
        "\n",
        "# ------------------ Models ------------------\n",
        "def build_custom():\n",
        "    m = models.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(96,96,3)),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(8, activation='softmax')\n",
        "    ])\n",
        "    m.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "def build_mobilenet():\n",
        "    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96,96,3))\n",
        "    base.trainable = False\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    out = layers.Dense(8, activation='softmax')(x)\n",
        "    m = models.Model(base.input, out)\n",
        "    m.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "# ------------------ Train classification ------------------\n",
        "def quick_train(model, name):\n",
        "    print(f\"\\nTraining {name}\")\n",
        "    model.fit(X_train, y_cls_train, epochs=5, batch_size=16,\n",
        "              validation_split=0.1, verbose=1)\n",
        "    preds = model.predict(X_test)\n",
        "    y_pred_cls = preds.argmax(1)\n",
        "    y_true_cls = y_cls_test.argmax(1)\n",
        "    acc = accuracy_score(y_true_cls, y_pred_cls)\n",
        "    f1  = f1_score(y_true_cls, y_pred_cls, average='weighted')\n",
        "    print(f\"{name} Accuracy: {acc:.3f}  F1: {f1:.3f}\")\n",
        "    return acc, f1\n",
        "\n",
        "acc1,f1_1 = quick_train(build_custom(), \"CustomCNN\")\n",
        "acc2,f1_2 = quick_train(build_mobilenet(), \"MobileNetV2\")\n",
        "\n",
        "print(\"\\nComparison => CustomCNN Acc:{:.3f} F1:{:.3f} | MobileNetV2 Acc:{:.3f} F1:{:.3f}\"\n",
        "      .format(acc1,f1_1,acc2,f1_2))\n",
        "\n",
        "# ------------------ Regression heads for valence/arousal ------------------\n",
        "def build_regressor():\n",
        "    m = models.Sequential([\n",
        "        layers.Conv2D(16,(3,3),activation='relu',input_shape=(96,96,3)),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(32,(3,3),activation='relu'),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(32,activation='relu'),\n",
        "        layers.Dense(2)  # [valence, arousal]\n",
        "    ])\n",
        "    m.compile(optimizer='adam', loss='mse')\n",
        "    return m\n",
        "\n",
        "y_reg_train = np.stack([y_val_train, y_aro_train], axis=1)\n",
        "y_reg_test  = np.stack([y_val_test,  y_aro_test ], axis=1)\n",
        "\n",
        "reg = build_regressor()\n",
        "print(\"\\nTraining Valence/Arousal regressor\")\n",
        "reg.fit(X_train, y_reg_train, epochs=5, batch_size=16,\n",
        "        validation_split=0.1, verbose=1)\n",
        "pred = reg.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_reg_test, pred))\n",
        "corr_v = pearsonr(y_val_test, pred[:,0])[0]\n",
        "corr_a = pearsonr(y_aro_test, pred[:,1])[0]\n",
        "print(f\"Valence/Arousal RMSE:{rmse:.3f}  Corr V:{corr_v:.3f}  Corr A:{corr_a:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, numpy as np, cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "IMG_DIR = \"/content/drive/MyDrive/Dataset/images\"\n",
        "ANN_DIR = \"/content/drive/MyDrive/Dataset/annotations\"\n",
        "\n",
        "# ---------- Load Data ----------\n",
        "def load_dataset(limit=None, size=124):\n",
        "    X, y_cls, y_val, y_aro = [], [], [], []\n",
        "    files = glob.glob(os.path.join(IMG_DIR, \"*.jpg\"))\n",
        "    if limit: files = files[:limit]\n",
        "    for p in files:\n",
        "        stem = os.path.splitext(os.path.basename(p))[0]\n",
        "        try:\n",
        "            exp = np.load(os.path.join(ANN_DIR, f\"{stem}_exp.npy\"))\n",
        "            val = np.load(os.path.join(ANN_DIR, f\"{stem}_val.npy\"))\n",
        "            aro = np.load(os.path.join(ANN_DIR, f\"{stem}_aro.npy\"))\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "        img = cv2.cvtColor(cv2.imread(p), cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (size, size))\n",
        "        X.append(img/255.)\n",
        "        y_cls.append(int(exp))\n",
        "        y_val.append(float(val))\n",
        "        y_aro.append(float(aro))\n",
        "    X = np.array(X, dtype=\"float32\")\n",
        "    y_cls = to_categorical(y_cls, num_classes=8)\n",
        "    return X, y_cls, np.array(y_val), np.array(y_aro)\n",
        "\n",
        "print(\"Loading full dataset …\")\n",
        "X, y_cls, y_val, y_aro = load_dataset(size=124)\n",
        "print(\"Total samples:\", len(X))\n",
        "\n",
        "X_train, X_test, y_cls_train, y_cls_test, y_val_train, y_val_test, y_aro_train, y_aro_test = \\\n",
        "    train_test_split(X, y_cls, y_val, y_aro, test_size=0.2, random_state=42)\n",
        "\n",
        "# ---------- Augmentation ----------\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# ---------- Fine-tunable MobileNet ----------\n",
        "def build_mobilenet_finetune():\n",
        "    base = MobileNetV2(weights='imagenet', include_top=False,\n",
        "                       input_shape=(124,124,3))\n",
        "    base.trainable = False  # frozen first\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    out = layers.Dense(8, activation='softmax')(x)\n",
        "    model = models.Model(base.input, out)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model, base\n",
        "\n",
        "# ---------- Train with staged unfreeze ----------\n",
        "# ---------------- Train with staged unfreeze (fixed) ----------------\n",
        "def train_mobilenet():\n",
        "    model, base = build_mobilenet_finetune()\n",
        "    es = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
        "    lr_sched = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "\n",
        "    # ✅ manual validation split\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_train, y_cls_train, test_size=0.1, random_state=42)\n",
        "\n",
        "    print(\"\\nStage 1: frozen base\")\n",
        "    model.fit(datagen.flow(X_tr, y_tr, batch_size=32),\n",
        "              validation_data=(X_val, y_val),\n",
        "              epochs=5,\n",
        "              callbacks=[es, lr_sched],\n",
        "              verbose=1)\n",
        "\n",
        "    print(\"\\nStage 2: unfreeze top 20 layers\")\n",
        "    for layer in base.layers[-20:]:\n",
        "        layer.trainable = True\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(datagen.flow(X_tr, y_tr, batch_size=32),\n",
        "              validation_data=(X_val, y_val),\n",
        "              epochs=20,\n",
        "              callbacks=[es, lr_sched],\n",
        "              verbose=1)\n",
        "    return model\n",
        "\n",
        "\n",
        "model = train_mobilenet()\n",
        "\n",
        "# ---------- Evaluation ----------\n",
        "preds = model.predict(X_test)\n",
        "y_pred_cls = preds.argmax(1)\n",
        "y_true_cls = y_cls_test.argmax(1)\n",
        "acc = accuracy_score(y_true_cls, y_pred_cls)\n",
        "f1  = f1_score(y_true_cls, y_pred_cls, average='weighted')\n",
        "print(f\"MobileNetV2 Fine-tuned  Acc:{acc:.3f}  F1:{f1:.3f}\")\n",
        "\n",
        "# ---------- Valence/Arousal Regressor ----------\n",
        "def build_regressor():\n",
        "    m = models.Sequential([\n",
        "        layers.Conv2D(32,(3,3),activation='relu',input_shape=(124,124,3)),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64,(3,3),activation='relu'),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(64,activation='relu'),\n",
        "        layers.Dense(2)\n",
        "    ])\n",
        "    m.compile(optimizer='adam', loss='mse')\n",
        "    return m\n",
        "\n",
        "y_reg_train = np.stack([y_val_train, y_aro_train], axis=1)\n",
        "y_reg_test  = np.stack([y_val_test,  y_aro_test ], axis=1)\n",
        "\n",
        "reg = build_regressor()\n",
        "print(\"\\nTraining Valence/Arousal regressor\")\n",
        "reg.fit(datagen.flow(X_train, y_reg_train, batch_size=32),\n",
        "        validation_split=0.1,\n",
        "        epochs=20,\n",
        "        callbacks=[EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)],\n",
        "        verbose=1)\n",
        "pred = reg.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_reg_test, pred))\n",
        "corr_v = pearsonr(y_val_test, pred[:,0])[0]\n",
        "corr_a = pearsonr(y_aro_test, pred[:,1])[0]\n",
        "print(f\"Val/Aro RMSE:{rmse:.3f}  CorrV:{corr_v:.3f}  CorrA:{corr_a:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1Kw7Q40oNDNU",
        "outputId": "861b409a-264c-4166-dcd6-b5a460f839b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading full dataset …\n",
            "Total samples: 3999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-881170184.py:55: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = MobileNetV2(weights='imagenet', include_top=False,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stage 1: frozen base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 554ms/step - accuracy: 0.1533 - loss: 2.4261 - val_accuracy: 0.2438 - val_loss: 2.1424 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 532ms/step - accuracy: 0.2529 - loss: 2.0233 - val_accuracy: 0.2625 - val_loss: 2.1185 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 513ms/step - accuracy: 0.3009 - loss: 1.9102 - val_accuracy: 0.2656 - val_loss: 2.0113 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 590ms/step - accuracy: 0.3012 - loss: 1.8450 - val_accuracy: 0.2469 - val_loss: 1.9732 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 537ms/step - accuracy: 0.3322 - loss: 1.7503 - val_accuracy: 0.2656 - val_loss: 1.9814 - learning_rate: 0.0010\n",
            "\n",
            "Stage 2: unfreeze top 20 layers\n",
            "Epoch 1/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 691ms/step - accuracy: 0.2174 - loss: 2.0835 - val_accuracy: 0.2531 - val_loss: 1.9748 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 662ms/step - accuracy: 0.2485 - loss: 1.9663 - val_accuracy: 0.2562 - val_loss: 1.9658 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 646ms/step - accuracy: 0.2751 - loss: 1.9239 - val_accuracy: 0.2438 - val_loss: 1.9627 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 666ms/step - accuracy: 0.2773 - loss: 1.8809 - val_accuracy: 0.2406 - val_loss: 1.9693 - learning_rate: 1.0000e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 642ms/step - accuracy: 0.3045 - loss: 1.8187 - val_accuracy: 0.2469 - val_loss: 1.9691 - learning_rate: 1.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 648ms/step - accuracy: 0.3278 - loss: 1.8138 - val_accuracy: 0.2469 - val_loss: 1.9629 - learning_rate: 5.0000e-06\n",
            "Epoch 7/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 664ms/step - accuracy: 0.3213 - loss: 1.7940 - val_accuracy: 0.2406 - val_loss: 1.9576 - learning_rate: 5.0000e-06\n",
            "Epoch 8/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 642ms/step - accuracy: 0.3286 - loss: 1.7652 - val_accuracy: 0.2313 - val_loss: 1.9511 - learning_rate: 5.0000e-06\n",
            "Epoch 9/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 626ms/step - accuracy: 0.3476 - loss: 1.7798 - val_accuracy: 0.2313 - val_loss: 1.9488 - learning_rate: 5.0000e-06\n",
            "Epoch 10/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 627ms/step - accuracy: 0.3243 - loss: 1.7842 - val_accuracy: 0.2406 - val_loss: 1.9448 - learning_rate: 5.0000e-06\n",
            "Epoch 11/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 633ms/step - accuracy: 0.3598 - loss: 1.7279 - val_accuracy: 0.2344 - val_loss: 1.9389 - learning_rate: 5.0000e-06\n",
            "Epoch 12/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 619ms/step - accuracy: 0.3637 - loss: 1.7389 - val_accuracy: 0.2500 - val_loss: 1.9342 - learning_rate: 5.0000e-06\n",
            "Epoch 13/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 629ms/step - accuracy: 0.3563 - loss: 1.7304 - val_accuracy: 0.2438 - val_loss: 1.9295 - learning_rate: 5.0000e-06\n",
            "Epoch 14/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 626ms/step - accuracy: 0.3500 - loss: 1.7293 - val_accuracy: 0.2469 - val_loss: 1.9237 - learning_rate: 5.0000e-06\n",
            "Epoch 15/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 624ms/step - accuracy: 0.3578 - loss: 1.6983 - val_accuracy: 0.2469 - val_loss: 1.9215 - learning_rate: 5.0000e-06\n",
            "Epoch 16/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 630ms/step - accuracy: 0.3736 - loss: 1.6909 - val_accuracy: 0.2500 - val_loss: 1.9146 - learning_rate: 5.0000e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 622ms/step - accuracy: 0.3616 - loss: 1.6926 - val_accuracy: 0.2469 - val_loss: 1.9103 - learning_rate: 5.0000e-06\n",
            "Epoch 18/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 608ms/step - accuracy: 0.4014 - loss: 1.6299 - val_accuracy: 0.2500 - val_loss: 1.9082 - learning_rate: 5.0000e-06\n",
            "Epoch 19/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 639ms/step - accuracy: 0.3655 - loss: 1.6855 - val_accuracy: 0.2594 - val_loss: 1.9079 - learning_rate: 5.0000e-06\n",
            "Epoch 20/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 623ms/step - accuracy: 0.3788 - loss: 1.6489 - val_accuracy: 0.2531 - val_loss: 1.9032 - learning_rate: 5.0000e-06\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 338ms/step\n",
            "MobileNetV2 Fine-tuned  Acc:0.291  F1:0.288\n",
            "\n",
            "Training Valence/Arousal regressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Argument `validation_split` is only supported for tensors or NumPy arrays.Found incompatible type in the input: [<class 'keras.src.legacy.preprocessing.image.NumpyArrayIterator'>]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-881170184.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_regressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining Valence/Arousal regressor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m reg.fit(datagen.flow(X_train, y_reg_train, batch_size=32),\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/array_slicing.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0munsplitable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_arrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcan_slice_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munsplitable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0;34m\"Argument `validation_split` is only supported \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;34m\"for tensors or NumPy arrays.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Argument `validation_split` is only supported for tensors or NumPy arrays.Found incompatible type in the input: [<class 'keras.src.legacy.preprocessing.image.NumpyArrayIterator'>]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Final"
      ],
      "metadata": {
        "id": "t2K3xpEPdBcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, numpy as np, cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
        "from scipy.stats import pearsonr\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# dataset paths\n",
        "IMG_DIR = \"/content/drive/MyDrive/Dataset/images\"\n",
        "ANN_DIR = \"/content/drive/MyDrive/Dataset/annotations\""
      ],
      "metadata": {
        "id": "49zoCrIypu4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(limit=None, size=124):\n",
        "    X, y_cls, y_val, y_aro = [], [], [], []\n",
        "    files = glob.glob(os.path.join(IMG_DIR, \"*.jpg\"))\n",
        "    if limit: files = files[:limit]\n",
        "    for p in files:\n",
        "        stem = os.path.splitext(os.path.basename(p))[0]\n",
        "        try:\n",
        "            exp = np.load(os.path.join(ANN_DIR, f\"{stem}_exp.npy\"))\n",
        "            val = np.load(os.path.join(ANN_DIR, f\"{stem}_val.npy\"))\n",
        "            aro = np.load(os.path.join(ANN_DIR, f\"{stem}_aro.npy\"))\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "        img = cv2.cvtColor(cv2.imread(p), cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (size, size))\n",
        "        X.append(img/255.)\n",
        "        y_cls.append(int(exp))\n",
        "        y_val.append(float(val))\n",
        "        y_aro.append(float(aro))\n",
        "    X = np.array(X, dtype=\"float32\")\n",
        "    y_cls = to_categorical(y_cls, num_classes=8)\n",
        "    return X, y_cls, np.array(y_val), np.array(y_aro)\n",
        "\n",
        "print(\"Loading dataset …\")\n",
        "X, y_cls, y_val, y_aro = load_dataset(size=124)\n",
        "print(\"Total samples:\", len(X))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qZ4BJwNpwVe",
        "outputId": "c70196c3-5dfd-4d96-ac33-72520d7e90fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset …\n",
            "Total samples: 3999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_cls_train, y_cls_test, y_val_train, y_val_test, y_aro_train, y_aro_test = \\\n",
        "    train_test_split(X, y_cls, y_val, y_aro, test_size=0.2, random_state=42)\n",
        "\n",
        "# Augment only training set\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(X_train)\n"
      ],
      "metadata": {
        "id": "Ur6aRbivpx5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mobilenet_finetune():\n",
        "    base = MobileNetV2(weights='imagenet', include_top=False,\n",
        "                       input_shape=(124,124,3))\n",
        "    base.trainable = False\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    out = layers.Dense(8, activation='softmax')(x)\n",
        "    model = models.Model(base.input, out)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model, base\n",
        "\n",
        "def train_mobilenet():\n",
        "    model, base = build_mobilenet_finetune()\n",
        "    es = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
        "    lr_sched = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "\n",
        "    # explicit validation split\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X_train, y_cls_train, test_size=0.1, random_state=42)\n",
        "\n",
        "    print(\"\\nStage 1: frozen base\")\n",
        "    model.fit(datagen.flow(X_tr, y_tr, batch_size=32),\n",
        "              validation_data=(X_val, y_val),\n",
        "              epochs=5, callbacks=[es, lr_sched], verbose=1)\n",
        "\n",
        "    print(\"\\nStage 2: unfreeze top 20 layers\")\n",
        "    for layer in base.layers[-20:]:\n",
        "        layer.trainable = True\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(datagen.flow(X_tr, y_tr, batch_size=32),\n",
        "              validation_data=(X_val, y_val),\n",
        "              epochs=20, callbacks=[es, lr_sched], verbose=1)\n",
        "    return model\n",
        "\n",
        "model = train_mobilenet()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT8DoaXAq8B3",
        "outputId": "6e845d78-38ff-4740-e918-b95b07295d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-759463891.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base = MobileNetV2(weights='imagenet', include_top=False,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stage 1: frozen base\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 556ms/step - accuracy: 0.1715 - loss: 2.5567 - val_accuracy: 0.2344 - val_loss: 2.0666 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 535ms/step - accuracy: 0.2438 - loss: 2.0376 - val_accuracy: 0.2719 - val_loss: 1.9945 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 512ms/step - accuracy: 0.2859 - loss: 1.8945 - val_accuracy: 0.2750 - val_loss: 1.9758 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 523ms/step - accuracy: 0.3080 - loss: 1.8360 - val_accuracy: 0.2844 - val_loss: 1.9667 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 504ms/step - accuracy: 0.3234 - loss: 1.8054 - val_accuracy: 0.2906 - val_loss: 1.9812 - learning_rate: 0.0010\n",
            "\n",
            "Stage 2: unfreeze top 20 layers\n",
            "Epoch 1/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 657ms/step - accuracy: 0.2224 - loss: 2.0676 - val_accuracy: 0.2500 - val_loss: 1.9674 - learning_rate: 1.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 639ms/step - accuracy: 0.2617 - loss: 1.9737 - val_accuracy: 0.2562 - val_loss: 1.9604 - learning_rate: 1.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 632ms/step - accuracy: 0.2689 - loss: 1.9355 - val_accuracy: 0.2562 - val_loss: 1.9483 - learning_rate: 1.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 637ms/step - accuracy: 0.2852 - loss: 1.8768 - val_accuracy: 0.2594 - val_loss: 1.9359 - learning_rate: 1.0000e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 659ms/step - accuracy: 0.3258 - loss: 1.8254 - val_accuracy: 0.2594 - val_loss: 1.9237 - learning_rate: 1.0000e-05\n",
            "Epoch 6/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 634ms/step - accuracy: 0.3224 - loss: 1.7944 - val_accuracy: 0.2750 - val_loss: 1.9129 - learning_rate: 1.0000e-05\n",
            "Epoch 7/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 700ms/step - accuracy: 0.3359 - loss: 1.7951 - val_accuracy: 0.2625 - val_loss: 1.9075 - learning_rate: 1.0000e-05\n",
            "Epoch 8/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 649ms/step - accuracy: 0.3343 - loss: 1.7675 - val_accuracy: 0.2656 - val_loss: 1.9080 - learning_rate: 1.0000e-05\n",
            "Epoch 9/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 635ms/step - accuracy: 0.3505 - loss: 1.7384 - val_accuracy: 0.2500 - val_loss: 1.9043 - learning_rate: 1.0000e-05\n",
            "Epoch 10/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 637ms/step - accuracy: 0.3589 - loss: 1.7135 - val_accuracy: 0.2594 - val_loss: 1.8969 - learning_rate: 1.0000e-05\n",
            "Epoch 11/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 631ms/step - accuracy: 0.3691 - loss: 1.7117 - val_accuracy: 0.2656 - val_loss: 1.8879 - learning_rate: 1.0000e-05\n",
            "Epoch 12/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 636ms/step - accuracy: 0.3971 - loss: 1.6429 - val_accuracy: 0.2906 - val_loss: 1.8796 - learning_rate: 1.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 650ms/step - accuracy: 0.3825 - loss: 1.6440 - val_accuracy: 0.2937 - val_loss: 1.8725 - learning_rate: 1.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 636ms/step - accuracy: 0.4076 - loss: 1.6301 - val_accuracy: 0.2906 - val_loss: 1.8705 - learning_rate: 1.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 659ms/step - accuracy: 0.4116 - loss: 1.6082 - val_accuracy: 0.2906 - val_loss: 1.8607 - learning_rate: 1.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 653ms/step - accuracy: 0.4144 - loss: 1.5876 - val_accuracy: 0.3063 - val_loss: 1.8538 - learning_rate: 1.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 632ms/step - accuracy: 0.4265 - loss: 1.5791 - val_accuracy: 0.3031 - val_loss: 1.8445 - learning_rate: 1.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 654ms/step - accuracy: 0.4228 - loss: 1.5627 - val_accuracy: 0.3125 - val_loss: 1.8433 - learning_rate: 1.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 656ms/step - accuracy: 0.4396 - loss: 1.5501 - val_accuracy: 0.3000 - val_loss: 1.8498 - learning_rate: 1.0000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 629ms/step - accuracy: 0.4357 - loss: 1.5369 - val_accuracy: 0.3031 - val_loss: 1.8461 - learning_rate: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(X_test)\n",
        "y_pred_cls = preds.argmax(1)\n",
        "y_true_cls = y_cls_test.argmax(1)\n",
        "acc = accuracy_score(y_true_cls, y_pred_cls)\n",
        "f1  = f1_score(y_true_cls, y_pred_cls, average='weighted')\n",
        "print(f\"MobileNetV2 Fine-tuned  Acc:{acc:.3f}  F1:{f1:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2ihikQq9a8",
        "outputId": "ae566fc3-3964-457a-f19e-c32c3466f820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 343ms/step\n",
            "MobileNetV2 Fine-tuned  Acc:0.296  F1:0.303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_regressor():\n",
        "    m = models.Sequential([\n",
        "        layers.Input(shape=(124,124,3)),\n",
        "        layers.Conv2D(32,(3,3),activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(64,(3,3),activation='relu'),\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(64,activation='relu'),\n",
        "        layers.Dense(2)\n",
        "    ])\n",
        "    m.compile(optimizer='adam', loss='mse')\n",
        "    return m\n",
        "\n",
        "# prepare regression targets\n",
        "y_reg_train = np.stack([y_val_train, y_aro_train], axis=1)\n",
        "y_reg_test  = np.stack([y_val_test,  y_aro_test ], axis=1)\n",
        "\n",
        "reg = build_regressor()\n",
        "print(\"\\nTraining Valence/Arousal regressor\")\n",
        "\n",
        "# explicit validation set, not validation_split\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X_train, y_reg_train, test_size=0.1, random_state=42)\n",
        "\n",
        "reg.fit(datagen.flow(X_tr, y_tr, batch_size=32),\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=20,\n",
        "        callbacks=[EarlyStopping(monitor='val_loss', patience=4,\n",
        "                                 restore_best_weights=True)],\n",
        "        verbose=1)\n",
        "\n",
        "pred = reg.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_reg_test, pred))\n",
        "corr_v = pearsonr(y_val_test, pred[:,0])[0]\n",
        "corr_a = pearsonr(y_aro_test, pred[:,1])[0]\n",
        "print(f\"Val/Aro RMSE:{rmse:.3f}  CorrV:{corr_v:.3f}  CorrA:{corr_a:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBe_B5vwq_Ma",
        "outputId": "53d4a8ff-8e8f-4de9-ec72-23b53b143f12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Valence/Arousal regressor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 759ms/step - loss: 0.1959 - val_loss: 0.1904\n",
            "Epoch 2/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 732ms/step - loss: 0.1847 - val_loss: 0.1849\n",
            "Epoch 3/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 722ms/step - loss: 0.1813 - val_loss: 0.1853\n",
            "Epoch 4/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 728ms/step - loss: 0.1817 - val_loss: 0.1854\n",
            "Epoch 5/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 724ms/step - loss: 0.1807 - val_loss: 0.1854\n",
            "Epoch 6/20\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 724ms/step - loss: 0.1774 - val_loss: 0.1851\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step\n",
            "Val/Aro RMSE:0.425  CorrV:0.061  CorrA:0.042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ECG1B37JrCZD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}